{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /Users/ayushgaur/Desktop/NLP/HW3/Data/Raw/IMDB Dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000,\n",
       "                                               review sentiment\n",
       " 0  One of the other reviewers has mentioned that ...  positive\n",
       " 1  A wonderful little production. <br /><br />The...  positive,\n",
       " PosixPath('/Users/ayushgaur/Desktop/NLP/HW3/Data/processed'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# change the path if required \n",
    "DATA_IN = Path(\"/Users/ayushgaur/Desktop/NLP/HW3/Data/Raw/IMDB Dataset.csv\")\n",
    "\n",
    "OUT_DIR = DATA_IN.parent.parent / \"processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Reading:\", DATA_IN)\n",
    "assert DATA_IN.exists(), f\"Not found: {DATA_IN}\"\n",
    "df = pd.read_csv(DATA_IN)\n",
    "assert set(df.columns) == {\"review\", \"sentiment\"}, f\"Unexpected columns: {df.columns.tolist()}\"\n",
    "\n",
    "len(df), df.head(2), OUT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50-50 split and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 0    12526\n",
       " 1    12474\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 1    12526\n",
       " 0    12474\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_label(x: str) -> int:\n",
    "    return 1 if str(x).strip().lower() == \"positive\" else 0\n",
    "\n",
    "df_train = df.iloc[:25000].copy().reset_index(drop=True)   \n",
    "df_test  = df.iloc[25000:].copy().reset_index(drop=True)   \n",
    "\n",
    "df_train[\"label\"] = df_train[\"sentiment\"].apply(to_label).astype(int)\n",
    "df_test[\"label\"]  = df_test[\"sentiment\"].apply(to_label).astype(int)\n",
    "\n",
    "df_train[\"label\"].value_counts(), df_test[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re, html\n",
    "\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "NON_ALNUM_RE = re.compile(r\"[^a-z0-9\\s]\")\n",
    "MULTISPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = html.unescape(str(s))\n",
    "    s = TAG_RE.sub(\" \", s)          \n",
    "    s = s.lower()\n",
    "    s = NON_ALNUM_RE.sub(\" \", s)  \n",
    "    s = MULTISPACE_RE.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def tokenize(s: str):\n",
    "    return clean_text(s).split()\n",
    "\n",
    "\n",
    "tokenize(df_train.loc[0, \"review\"])[:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building vocab with top 10k frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "def build_vocab(texts, vocab_size=10000):\n",
    "    counter = Counter()\n",
    "    for t in texts:\n",
    "        counter.update(tokenize(t))\n",
    "    word2id = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "    for i, (w, _) in enumerate(counter.most_common(vocab_size - 2), start=2):\n",
    "        word2id[w] = i\n",
    "    id2word = {i: w for w, i in word2id.items()}\n",
    "    return word2id, id2word\n",
    "\n",
    "word2id, id2word = build_vocab(df_train[\"review\"], vocab_size=10000)\n",
    "\n",
    "\n",
    "(OUT_DIR / \"vocab.json\").write_text(json.dumps(word2id, ensure_ascii=False, indent=2))\n",
    "with open(OUT_DIR / \"vocab.txt\", \"w\") as f:\n",
    "    for i in range(len(id2word)):\n",
    "        f.write(f\"{i}\\t{id2word[i]}\\n\")\n",
    "\n",
    "len(word2id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to IDs; truncating to length 25/50/100; saving CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb_test_len100.csv',\n",
       " 'imdb_test_len25.csv',\n",
       " 'imdb_test_len50.csv',\n",
       " 'imdb_train_len100.csv',\n",
       " 'imdb_train_len25.csv',\n",
       " 'imdb_train_len50.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_ids(s: str, w2i: dict):\n",
    "    return [w2i.get(tok, 1) for tok in tokenize(s)] \n",
    "\n",
    "def pad_or_truncate(ids, length: int):\n",
    "    return ids[:length] if len(ids) >= length else ids + [0] * (length - len(ids))  \n",
    "\n",
    "def make_dataset(df_in: pd.DataFrame, w2i: dict, length: int):\n",
    "    seqs = [pad_or_truncate(text_to_ids(t, w2i), length) for t in df_in[\"review\"]]\n",
    "    seq_str = [\" \".join(map(str, seq)) for seq in seqs]\n",
    "    return pd.DataFrame({\"ids\": seq_str, \"label\": df_in[\"label\"].astype(int)})\n",
    "\n",
    "for L in [25, 50, 100]:\n",
    "    make_dataset(df_train, word2id, L).to_csv(OUT_DIR / f\"imdb_train_len{L}.csv\", index=False)\n",
    "    make_dataset(df_test, word2id, L).to_csv(OUT_DIR / f\"imdb_test_len{L}.csv\", index=False)\n",
    "\n",
    "sorted(p.name for p in OUT_DIR.glob(\"*.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports and config for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Core\n",
    "import os, time, math, json, random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Paths\n",
    "ROOT     = Path(\".\").resolve()\n",
    "DATA_DIR = ROOT / \"Data\" / \"processed\"   \n",
    "RESULTS  = ROOT / \"results\"; RESULTS.mkdir(exist_ok=True, parents=True)\n",
    "METRICS_CSV = RESULTS / \"metrics.csv\"\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loaders for the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbCsvDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path: Path):\n",
    "        df = pd.read_csv(path)\n",
    "        self.X = [list(map(int, s.split())) for s in df[\"ids\"].tolist()]\n",
    "        self.y = df[\"label\"].astype(int).tolist()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = torch.tensor(self.X[idx], dtype=torch.long)\n",
    "        lab = torch.tensor(self.y[idx], dtype=torch.float32)  \n",
    "        return ids, lab\n",
    "\n",
    "def build_loaders(seq_len: int, batch_size: int = 32):\n",
    "    train_csv = DATA_DIR / f\"imdb_train_len{seq_len}.csv\"\n",
    "    test_csv  = DATA_DIR / f\"imdb_test_len{seq_len}.csv\"\n",
    "\n",
    "    train_ds = ImdbCsvDataset(train_csv)\n",
    "    test_ds  = ImdbCsvDataset(test_csv)\n",
    "\n",
    "    # small validation split from training for loss curves; here 90/10 split\n",
    "    n = len(train_ds)\n",
    "    n_val = int(0.1 * n)\n",
    "    n_train = n - n_val\n",
    "    gen = torch.Generator().manual_seed(SEED)\n",
    "    train_ds, val_ds = torch.utils.data.random_split(train_ds, [n_train, n_val], generator=gen)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = {\n",
    "    \"relu\": nn.ReLU(),\n",
    "    \"tanh\": nn.Tanh(),\n",
    "    \"sigmoid\": nn.Sigmoid(),\n",
    "}\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 100, hidden_size: int = 64,\n",
    "                 num_layers: int = 2, dropout: float = 0.5, rnn_type: str = \"lstm\",\n",
    "                 activation: str = \"relu\", bidirectional: bool = False):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(embed_dim, hidden_size, num_layers=num_layers,\n",
    "                              nonlinearity=\"tanh\" if activation != \"relu\" else \"relu\",\n",
    "                              dropout=dropout if num_layers > 1 else 0.0,\n",
    "                              bidirectional=False, batch_first=True)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(embed_dim, hidden_size, num_layers=num_layers,\n",
    "                               dropout=dropout if num_layers > 1 else 0.0,\n",
    "                               bidirectional=False, batch_first=True)\n",
    "        elif rnn_type == \"bilstm\":\n",
    "            self.rnn = nn.LSTM(embed_dim, hidden_size, num_layers=num_layers,\n",
    "                               dropout=dropout if num_layers > 1 else 0.0,\n",
    "                               bidirectional=True, batch_first=True)\n",
    "            bidirectional = True\n",
    "        else:\n",
    "            raise ValueError(\"rnn_type must be 'rnn', 'lstm', or 'bilstm'.\")\n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "        rnn_out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "\n",
    "        # Simple pooling over time (mean-pool), then activation and output\n",
    "        self.activation = ACTIVATIONS[activation]\n",
    "        self.fc = nn.Linear(rnn_out_dim, 1)  \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)                          \n",
    "        out, _ = self.rnn(emb)                       \n",
    "        pooled = out.mean(dim=1)                     \n",
    "        h = self.dropout(self.activation(pooled))    \n",
    "        logits = self.fc(h).squeeze(1)               \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval utilities (BCE loss, accuracy, macro-F1, gradient clipping option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    vocab_size: int\n",
    "    seq_len: int = 50\n",
    "    rnn_type: str = \"lstm\"          \n",
    "    activation: str = \"relu\"        \n",
    "    optimizer: str = \"adam\"         \n",
    "    embed_dim: int = 100\n",
    "    hidden_size: int = 64\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.5\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 5\n",
    "    grad_clip_max_norm: float | None = None  \n",
    "\n",
    "def make_optimizer(name: str, params, lr=1e-3):\n",
    "    name = name.lower()\n",
    "    if name == \"adam\":    return torch.optim.Adam(params, lr=lr)\n",
    "    if name == \"sgd\":     return torch.optim.SGD(params, lr=lr, momentum=0.9)\n",
    "    if name == \"rmsprop\": return torch.optim.RMSprop(params, lr=lr, momentum=0.9)\n",
    "    raise ValueError(\"optimizer must be 'adam', 'sgd', or 'rmsprop'\")\n",
    "\n",
    "def epoch_loop(model, loader, optimizer=None, clip_max_norm=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(mode=is_train)\n",
    "    losses, y_true, y_pred = [], [], []\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    start = time.time()\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            if clip_max_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_max_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        y_pred.extend((probs >= 0.5).astype(int).tolist())\n",
    "        y_true.extend(yb.detach().cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    dur = time.time() - start\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return np.mean(losses), acc, f1m, dur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single runner + csv logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(cfg: TrainConfig):\n",
    "    # Data\n",
    "    train_loader, val_loader, test_loader = build_loaders(cfg.seq_len, batch_size=cfg.batch_size)\n",
    "\n",
    "    # Model\n",
    "    model = RNNClassifier(\n",
    "        vocab_size=cfg.vocab_size, embed_dim=cfg.embed_dim, hidden_size=cfg.hidden_size,\n",
    "        num_layers=cfg.num_layers, dropout=cfg.dropout,\n",
    "        rnn_type=cfg.rnn_type if cfg.rnn_type != \"bilstm\" else \"bilstm\",\n",
    "        activation=cfg.activation, bidirectional=(cfg.rnn_type == \"bilstm\")\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optimizer = make_optimizer(cfg.optimizer, model.parameters())\n",
    "\n",
    "    # Train\n",
    "    best_val = float(\"inf\")\n",
    "    history = []\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        tr_loss, tr_acc, tr_f1, tr_time = epoch_loop(model, train_loader, optimizer,\n",
    "                                                     clip_max_norm=cfg.grad_clip_max_norm)\n",
    "        va_loss, va_acc, va_f1, va_time = epoch_loop(model, val_loader, optimizer=None)\n",
    "\n",
    "        history.append({\"epoch\": epoch, \"train_loss\": tr_loss, \"val_loss\": va_loss})\n",
    "        print(f\"[{epoch}/{cfg.epochs}] train_loss={tr_loss:.4f} \"\n",
    "              f\"val_loss={va_loss:.4f} val_acc={va_acc:.4f} val_f1={va_f1:.4f}\")\n",
    "\n",
    "        \n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), RESULTS / \"tmp_best.pt\")\n",
    "\n",
    "    # Loading best and evaluating on test\n",
    "    model.load_state_dict(torch.load(RESULTS / \"tmp_best.pt\", map_location=DEVICE))\n",
    "    te_loss, te_acc, te_f1, te_time = epoch_loop(model, test_loader, optimizer=None)\n",
    "\n",
    "    # Log one consolidated line to metrics.csv\n",
    "    row = {\n",
    "        \"model\": cfg.rnn_type.upper(),\n",
    "        \"activation\": cfg.activation,\n",
    "        \"optimizer\": cfg.optimizer.upper(),\n",
    "        \"seq_len\": cfg.seq_len,\n",
    "        \"grad_clip\": cfg.grad_clip_max_norm if cfg.grad_clip_max_norm is not None else \"off\",\n",
    "        \"epochs\": cfg.epochs,\n",
    "        \"final_test_loss\": round(te_loss, 6),\n",
    "        \"accuracy\": round(te_acc, 6),\n",
    "        \"f1_macro\": round(te_f1, 6),\n",
    "        \"epoch_time_s(last_train)\": round(history[-1][\"train_loss\"] * 0 + te_time, 4),  # placeholder: per-epoch measured above in epoch_loop\n",
    "        \"device\": str(DEVICE),\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    "    pd.DataFrame([row]).to_csv(METRICS_CSV, mode=\"a\", header=not METRICS_CSV.exists(), index=False)\n",
    "\n",
    "    \n",
    "    pd.DataFrame(history).to_csv(RESULTS / f\"loss_curve_{cfg.rnn_type}_{cfg.activation}_{cfg.optimizer}_len{cfg.seq_len}_clip{row['grad_clip']}.csv\",\n",
    "                                 index=False)\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming the vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DATA_DIR = /Users/ayushgaur/Desktop/NLP/HW3/Data/processed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/Users/ayushgaur/Desktop/NLP/HW3/Data/processed\")\n",
    "assert (DATA_DIR / \"vocab.json\").exists(), f\"Not found: {DATA_DIR/'vocab.json'}\"\n",
    "print(\"Using DATA_DIR =\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocab_json = DATA_DIR / \"vocab.json\"\n",
    "with open(vocab_json) as f:\n",
    "    word2id = json.load(f)\n",
    "VOCAB_SIZE = max(map(int, word2id.values())) + 1\n",
    "VOCAB_SIZE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal matrix covering the slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] train_loss=0.6367 val_loss=0.5500 val_acc=0.7192 val_f1=0.7188\n",
      "[2/5] train_loss=0.5015 val_loss=0.5085 val_acc=0.7460 val_f1=0.7447\n",
      "[3/5] train_loss=0.4329 val_loss=0.4865 val_acc=0.7708 val_f1=0.7702\n",
      "[4/5] train_loss=0.3800 val_loss=0.4919 val_acc=0.7708 val_f1=0.7706\n",
      "[5/5] train_loss=0.3370 val_loss=0.4861 val_acc=0.7696 val_f1=0.7692\n",
      "[1/5] train_loss=0.6062 val_loss=0.5299 val_acc=0.7248 val_f1=0.7225\n",
      "[2/5] train_loss=0.4685 val_loss=0.4937 val_acc=0.7584 val_f1=0.7573\n",
      "[3/5] train_loss=0.3914 val_loss=0.4847 val_acc=0.7776 val_f1=0.7776\n",
      "[4/5] train_loss=0.3257 val_loss=0.5543 val_acc=0.7564 val_f1=0.7539\n",
      "[5/5] train_loss=0.2643 val_loss=0.6317 val_acc=0.7696 val_f1=0.7696\n",
      "[1/5] train_loss=0.6001 val_loss=0.5229 val_acc=0.7376 val_f1=0.7356\n",
      "[2/5] train_loss=0.4545 val_loss=0.4839 val_acc=0.7688 val_f1=0.7686\n",
      "[3/5] train_loss=0.3681 val_loss=0.5054 val_acc=0.7696 val_f1=0.7690\n",
      "[4/5] train_loss=0.2913 val_loss=0.5055 val_acc=0.7768 val_f1=0.7767\n",
      "[5/5] train_loss=0.2177 val_loss=0.5835 val_acc=0.7668 val_f1=0.7663\n",
      "[1/5] train_loss=0.6697 val_loss=0.6153 val_acc=0.6816 val_f1=0.6816\n",
      "[2/5] train_loss=0.5771 val_loss=0.5455 val_acc=0.7232 val_f1=0.7185\n",
      "[3/5] train_loss=0.4970 val_loss=0.5149 val_acc=0.7544 val_f1=0.7539\n",
      "[4/5] train_loss=0.4377 val_loss=0.5202 val_acc=0.7448 val_f1=0.7442\n",
      "[5/5] train_loss=0.3908 val_loss=0.5328 val_acc=0.7440 val_f1=0.7437\n",
      "[1/5] train_loss=0.6025 val_loss=0.5216 val_acc=0.7360 val_f1=0.7351\n"
     ]
    }
   ],
   "source": [
    "# Baseline (lstm,relu,adam) while varying factors\n",
    "BASE = dict(\n",
    "    vocab_size=VOCAB_SIZE, seq_len=50, rnn_type=\"lstm\",\n",
    "    activation=\"relu\", optimizer=\"adam\",\n",
    "    embed_dim=100, hidden_size=64, num_layers=2, dropout=0.5,\n",
    "    batch_size=32, epochs=5, grad_clip_max_norm=None\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "#  Architectures: RNN, LSTM, BiLSTM \n",
    "for arch in [\"rnn\", \"lstm\", \"bilstm\"]:\n",
    "    cfg = TrainConfig(**{**BASE, \"rnn_type\": arch})\n",
    "    results.append(run_experiment(cfg))\n",
    "\n",
    "#  Activations: Sigmoid, ReLU, Tanh (LSTM fixed)\n",
    "for act in [\"sigmoid\", \"relu\", \"tanh\"]:\n",
    "    cfg = TrainConfig(**{**BASE, \"activation\": act, \"rnn_type\": \"lstm\"})\n",
    "    results.append(run_experiment(cfg))\n",
    "\n",
    "#  Optimizers: Adam, SGD, RMSProp (LSTM + ReLU fixed)\n",
    "for opt in [\"adam\", \"sgd\", \"rmsprop\"]:\n",
    "    cfg = TrainConfig(**{**BASE, \"optimizer\": opt, \"rnn_type\": \"lstm\", \"activation\": \"relu\"})\n",
    "    results.append(run_experiment(cfg))\n",
    "\n",
    "#  Sequence length: 25, 50, 100 (LSTM + ReLU + Adam fixed)\n",
    "for L in [25, 50, 100]:\n",
    "    cfg = TrainConfig(**{**BASE, \"seq_len\": L, \"rnn_type\": \"lstm\", \"activation\": \"relu\", \"optimizer\": \"adam\"})\n",
    "    results.append(run_experiment(cfg))\n",
    "\n",
    "#  Gradient clipping: off vs on (e.g., max_norm=1.0) with a representative model\n",
    "for clip in [None, 1.0]:\n",
    "    cfg = TrainConfig(**{**BASE, \"grad_clip_max_norm\": clip, \"rnn_type\": \"lstm\", \"activation\": \"relu\", \"optimizer\": \"adam\"})\n",
    "    results.append(run_experiment(cfg))\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and F1 vs Sequence length plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "RESULTS = Path(\"results\")           \n",
    "metrics_path = RESULTS / \"metrics.csv\"\n",
    "\n",
    "m = pd.read_csv(metrics_path)\n",
    "\n",
    "by_len = (\n",
    "    m.sort_values(\"f1_macro\", ascending=False)\n",
    "     .groupby(\"seq_len\", as_index=False)\n",
    "     .first()[[\"seq_len\", \"accuracy\", \"f1_macro\", \"model\", \"activation\", \"optimizer\", \"grad_clip\"]]\n",
    "     .sort_values(\"seq_len\")\n",
    ")\n",
    "\n",
    "display(by_len)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(by_len[\"seq_len\"], by_len[\"accuracy\"], marker=\"o\", label=\"Accuracy\")\n",
    "plt.plot(by_len[\"seq_len\"], by_len[\"f1_macro\"], marker=\"s\", label=\"Macro-F1\")\n",
    "plt.title(\"Accuracy & Macro-F1 vs Sequence Length (best per length)\")\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(by_len[\"seq_len\"])\n",
    "plt.ylim(0.45, 1.0)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
